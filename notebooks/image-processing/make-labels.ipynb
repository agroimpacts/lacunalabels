{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2d5a23d0-ab09-4858-b158-a140c134c146",
   "metadata": {},
   "source": [
    "# Make labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c62696f9-1043-4ba2-8913-4191f7cabb14",
   "metadata": {},
   "source": [
    "The labels from the highest quality assignment for each site were rasterized into 3 classes: non-field (0), field interior (1), and field edge, which provides the basis for training a boundary aware semantic segmentation model that can be used to more effectively separate individual fields. \n",
    "\n",
    "The resulting chips provide a single label for each image chip. Additional assignments for Class 1 and 4 sites are also available, and can be converted to chips for different purposes (e.g. to assess the impact of label noise on model predictions; Elmes et al, 2020). \n",
    "\n",
    "This notebook may also be adapted to create different types of labels, such as binary labels (field/no-field) or separate labels representing, for example, field edge, field interior, non-field, and distance to nearest field boundary (cite)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "255b886c-1d48-4a97-bcb3-8bc15388baae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import warnings\n",
    "from pathlib import Path\n",
    "import rioxarray as rxr\n",
    "import xarray as xr\n",
    "from rasterio.enums import Resampling\n",
    "from rasterio import features\n",
    "import geopandas as gpd\n",
    "from shapely.geometry import Polygon, box, mapping\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime as dt\n",
    "import multiprocessing as mp\n",
    "import leafmap.leafmap as leafmap"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e088e526-ce1c-41cd-8921-0d9f977586cf",
   "metadata": {},
   "source": [
    "## Set-up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e8f857ee-9332-45e8-a07f-058b73dd1eee",
   "metadata": {},
   "outputs": [],
   "source": [
    "root_dir = os.environ[\"HOME\"]\n",
    "proj_dir = Path(root_dir) / \"Dropbox/projects/lacunalabels\"\n",
    "data_dir = Path(root_dir) / \"labels\"\n",
    "chip_dir = Path(data_dir) / \"lacuna/images\"\n",
    "label_dir = Path(data_dir) / \"lacuna/labels\"\n",
    "final_dir = Path(proj_dir) / \"data/processed\"\n",
    "if not os.path.exists(label_dir):\n",
    "    os.makedirs(label_dir, exist_ok=True)\n",
    "log_path = Path(root_dir) / \"logs/label-maker2.log\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96f2a8b0-38be-4f79-96d1-0599c857aa2f",
   "metadata": {},
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c4134fdc-6062-458d-b1ea-6bb656ecbc1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_catalog(catalog, groups, metric, keep):\n",
    "    \"\"\"\n",
    "    Function to filter the full catalog by class and quality metric\n",
    "\n",
    "    Args:\n",
    "    catalog: DataFrame\n",
    "        The full catalog, read in\n",
    "    groups: List\n",
    "        A list of key-value pairs providing with possible keys of \"whole\" and \n",
    "        \"best\", with the values providing one or more of the label classes. \n",
    "        Classes corresponding to \"whole\" will have all assignments in the class\n",
    "        selected. \"Best\" will result in the best assignment \n",
    "        corresponding to the provided metric selected/\n",
    "    metric: str\n",
    "        One of the quality metrics in the catalog, e.g. Rscore, Qscore. Must be \n",
    "        provided if a key in groups is not \"whole\"\n",
    "    keep: list\n",
    "        Names of columns in the full catalog that should be kept in the \n",
    "        filtered catalog\n",
    "\n",
    "    Returns:\n",
    "        A DataFrame containing the filtered assignments, possibly with \n",
    "        duplicates. If so, you may wish to remove them by following up with a \n",
    "        `drop_duplicates()`\n",
    "    \"\"\"\n",
    "    out_catalog = []\n",
    "    for g in groups:\n",
    "        cls = list(g.values())[0]\n",
    "        cat = catalog.query(\"Class in @cls\")\n",
    "        if list(g.keys())[0] == \"whole\":\n",
    "            print(f\"Extracting all of Class {' and '.join(cls)}\")\n",
    "            out_catalog.append(cat)\n",
    "        elif list(g.keys())[0] == \"best\": \n",
    "            print(f\"Extracting best of Class {' and '.join(cls)}\")\n",
    "            out_catalog.append(\n",
    "                cat.groupby(\"name\")\n",
    "                .apply(lambda x: x.loc[[x[metric].idxmax()]] \n",
    "                       if not x[metric].isna().all() else x, \n",
    "                       include_groups=False)\n",
    "                .reset_index(level=[\"name\"])\n",
    "            )\n",
    "        else: \n",
    "            print(\"Use either 'whole' or 'best' as group keys\")\n",
    "            break \n",
    "\n",
    "    out_catalog = pd.concat(out_catalog, axis=0)[keep].reset_index(drop=True)\n",
    "    return out_catalog\n",
    "\n",
    "def threeclass_label(assignment, label_dir, fields, log=None, \n",
    "                     overwrite=True):\n",
    "    \"\"\"\n",
    "    Create a three class label (0: non-field, 1: field interior, \n",
    "    2: field boundary) with the same dimensions as the corresponding \n",
    "    image chip. \n",
    "\n",
    "    Args: \n",
    "    assignment: pandas.Series\n",
    "        A series representing one assignment from the label catalog\n",
    "    fields: geopandas.GeoDataFrame\n",
    "        The fields polygons, read in from the provided geoparquet file\n",
    "    label_dir: str or Path\n",
    "        Directory to write rasterized labels to\n",
    "    log: str or Path\n",
    "        Name and path of log file\n",
    "    overwrite: bool\n",
    "        Overwrite label if it exists on disk or not (default = True)\n",
    "    \"\"\"\n",
    "\n",
    "    lbl_name = f\"{re.sub(\".tif\", \"\", assignment.chip)}-\"\\\n",
    "        f\"{assignment.assignment_id}.tif\"\n",
    "    dst_path = Path(label_dir) / lbl_name\n",
    "\n",
    "    if not overwrite and os.path.exists(dst_path):\n",
    "       msg = f\"{os.path.basename(dst_path)} exists, skipping\"\n",
    "       print(msg, file=log, flush=True)\n",
    "\n",
    "    else: \n",
    "        chip = rxr.open_rasterio(Path(chip_dir) / assignment.chip)\n",
    "        \n",
    "        transform = chip.rio.transform()\n",
    "        _, r, c = chip.shape\n",
    "        res = np.mean([abs(transform[0]), abs(transform[4])])\n",
    "        \n",
    "        grid = gpd.GeoDataFrame(geometry=[box(*chip.rio.bounds())], \n",
    "                                crs=chip.rio.crs)\n",
    "        \n",
    "        out_arr = np.zeros((r, c)).astype('int16')\n",
    "        if assignment.nflds > 0:\n",
    "            \n",
    "            shp = fields.query(\"assignment_id==@row.assignment_id\").copy()\n",
    "    \n",
    "            shp[\"category\"] = 1\n",
    "            shp['buffer_in'] = shp.geometry.buffer(-res)\n",
    "            shp['buffer_out'] = shp.geometry.buffer(res)\n",
    "            shp = gpd.overlay(grid, shp, how='intersection')\n",
    "            out_arr = np.zeros((r, c)).astype('uint8')\n",
    "        \n",
    "            shapes = ((geom, value) \n",
    "                      for geom, value in zip(shp['geometry'], shp['category']))\n",
    "            burned = features.rasterize(shapes=shapes, fill=0, \n",
    "                                        out=out_arr.copy(), \n",
    "                                        transform=transform)\n",
    "            \n",
    "            try:\n",
    "                shapes_shrink = (\n",
    "                    (geom, value) \n",
    "                    for geom, value in zip(shp['buffer_in'], shp['category'])\n",
    "                )\n",
    "                shrunk = features.rasterize(\n",
    "                    shapes=shapes_shrink, fill=0, out=out_arr.copy(), \n",
    "                    transform=transform\n",
    "                )\n",
    "                shapes_explode = (\n",
    "                    (geom, value) \n",
    "                    for geom, value in zip(shp['buffer_out'], shp['category'])\n",
    "                )\n",
    "                exploded = features.rasterize(\n",
    "                    shapes=shapes_explode, fill=0, out=out_arr.copy(), \n",
    "                    transform=transform\n",
    "                )\n",
    "            except:\n",
    "                shp['buffer'] = shp.geometry.buffer(-res)\n",
    "                shapes_shrink = (\n",
    "                    (geom, value) \n",
    "                    for geom, value in zip(shp['buffer'], shp['category'])\n",
    "                )\n",
    "                shrunk = features.rasterize(\n",
    "                    shapes=shapes_shrink, fill=0, out=out_arr.copy(), \n",
    "                    transform=transform\n",
    "                )\n",
    "            \n",
    "            lbl = (\n",
    "                burned * 2 - shrunk + \\\n",
    "                np.where((exploded*2-burned)==1, 0, exploded*2-burned)\n",
    "                .astype(np.uint8)\n",
    "            )\n",
    "        else: \n",
    "            lbl = out_arr\n",
    "    \n",
    "        lbl_raster = xr.DataArray(\n",
    "            lbl,\n",
    "            dims=[\"y\", \"x\"],\n",
    "            coords={\"y\": chip.y, \"x\": chip.x},\n",
    "            attrs={\"transform\": transform, \"crs\": chip.rio.crs}\n",
    "        )\n",
    "\n",
    "        # check dimensions\n",
    "        try:\n",
    "            assert chip.rio.bounds() == lbl_raster.rio.bounds()\n",
    "        except AssertionError as err:\n",
    "            msg = f\"{dt.now()}: {os.path.basename(dst_path)} has incorrect bounds\"\n",
    "            print(msg, file=log, flush=True)\n",
    "            raise err\n",
    "        try:    \n",
    "            assert chip.shape[1:3] == lbl_raster.shape\n",
    "        except AssertionError as err:\n",
    "            msg = f\"{dt.now()}: {os.path.basename(dst_path)} incorrect output shape\"\n",
    "            print(msg, file=log, flush=True)\n",
    "            raise err\n",
    "\n",
    "        # write to disk\n",
    "        lbl_raster.rio.to_raster(dst_path)\n",
    "        msg = f\"{dt.now()}: created {os.path.basename(dst_path)}\"\n",
    "        print(msg, file=log, flush=True)\n",
    "\n",
    "    assignment_out = assignment.copy()\n",
    "    assignment_out[\"label\"] = lbl_name\n",
    "\n",
    "    return pd.DataFrame([assignment_out.to_list()], \n",
    "                        columns=assignment_out.index)\n",
    "\n",
    "def view_random_label(label_catalog, label_dir, chip_dir, bands=[1,2,3], \n",
    "                      seed=None): \n",
    "    \"\"\"\n",
    "    A leafmap-based viewer that enables comparison of a randomly selected\n",
    "    label against of the image chip\n",
    "\n",
    "    Args: \n",
    "    label_catalog: pandas.DataFrame\n",
    "        The processed label catalog\n",
    "    label_dir: str\n",
    "        The path to the label directory (not strings only, not Path)\n",
    "    chip_dir: str\n",
    "        The path to the image chip directory (not strings only, not Path)\n",
    "    bands: list\n",
    "        Specify band combination for the image chip. Defaults to [1,2,3] for \n",
    "        true color\n",
    "    seed: int\n",
    "        Defaults to None, but the same chip can be selected again if an integer\n",
    "        is provided\n",
    "\n",
    "    Returns: \n",
    "        A leafmap viewer\n",
    "    \"\"\"\n",
    "    random_label = label_catalog.sample(n=1, random_state=seed)\n",
    "    lbl_path = os.path.join(label_dir, random_label.label.iloc[0])\n",
    "    chip_path = os.path.join(chip_dir, random_label.chip.iloc[0])\n",
    "    lbl_name = re.sub(\".tif\", \"\", random_label.label.iloc[0])\n",
    "    m = leafmap.Map(\n",
    "        zoom=17, center=random_label[[\"y\", \"x\"]].iloc[0].to_list()\n",
    "    )\n",
    "    m.add_basemap(\"SATELLITE\")\n",
    "    m.add_raster(chip_path, bands=[1,2,3], layer_name='Image', \n",
    "                 zoom_to_layer=False)\n",
    "    m.add_raster(lbl_path, layer_name=lbl_name,zoom_to_layer=False)\n",
    "    return m"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b6882fe-6456-4ec2-9cbe-69ec34dbfee1",
   "metadata": {},
   "source": [
    "## Selecting a label catalog\n",
    "\n",
    "The label catalog provided here provides all labels collected during the project, with the exception of sites where image quality was insufficient to label (note: additional labels may have been retained with low image quality).  Labels are provided in the following classes:\n",
    "\n",
    "The labels have several distinct classes: \n",
    "\n",
    "-   Class 1a: A subset expert-labeled sites that were selected to serve as quality control sites (Q sites) in the labelling platform;\n",
    "\n",
    "-   Class 1b: Expert-labeled sites not used in the labelling platform for Quality control;\n",
    "\n",
    "-   Class 1c: Q control assignments completed by the labelling teams against Class 1a labels;\n",
    "\n",
    "-   Class 1d: Sites corresponding to Class 1b sites that were digitized by 1-3 members of the labeling team;\n",
    "\n",
    "-   Class 2: Ordinary mapping assignments, represented a single unique site mapped by a single labeller. An exception to this case of one labeller/one label were for those assignment marked as Untrusted, in which case it would have been mapped multiple times until the first approved assignment was completed. \n",
    "\n",
    "-   Class 4: Sites mapped by three separate labellers\n",
    "\n",
    "The catalog provides a range of quality metrics associated with the labels, with the following exceptions; \n",
    "\n",
    "- For Class 1a and 1b, no Qscores are available\n",
    "- For Class 1b, there are 153 sites for which no Rscore is available\n",
    "\n",
    "All labels are preserved in the catalog, as they may be useful for different purposes, such as: \n",
    "\n",
    "- Contructing quality-weighted consensus maps to:\n",
    "    1. Assess label uncertainty;\n",
    "    2. Extract pixel-based samples from area of higher certainty\n",
    "- Testing whether additional noisy labels added to training samples improve model performance;\n",
    "- Pass multiple labels for the same location into a model as a form of data-based regularization\n",
    "\n",
    "We provided an example here of one approach for selecting what is likely to be the best label for each site, using the following rules:\n",
    "\n",
    "- Drop:\n",
    "    - All assignments marked as Untrusted or Rejected;\n",
    "    - No Class 1c labels;\n",
    "- Keep:\n",
    "    - All Class 1a assignments;\n",
    "    - All Class 2 assignments;\n",
    "    - The assignment with the highest Rscore for each site occuring in one or both of the Class 1b and Class 1d samples;\n",
    "    - The assignment with the highest Rscore for each Class 4 site\n",
    "\n",
    "Alternative approaches may also be used for finding the best sample, such as using the highest Qscore per sample, or multiple individual Q metrics, e.g. the highest combination of Area and N metrics. It may also be preferrable to take the Class 1c assignment with the highest Qscore or highest Rscore for each Class 1a site, in place of the Class 1a labels. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84b619d7-8ff7-4d34-8ad9-ddc39419277f",
   "metadata": {},
   "source": [
    "### Read in catalog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ae3d704b-7534-44da-8396-7c125b70d242",
   "metadata": {},
   "outputs": [],
   "source": [
    "catalog = pd.read_csv(Path(proj_dir) /\\\n",
    "                      \"data/interim/label_catalog_allclasses.csv\", \n",
    "                      low_memory=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30224177-eea7-40ae-a207-ad568e37a171",
   "metadata": {},
   "source": [
    "### Apply filter\n",
    "\n",
    "To follow the selection example describe above, we first queried the catalog to drop Untrusted and Rejected assignments, then defined a grouping list with the key for \"whole\" Classes to be retained set at \"1a\" and \"2\", and two separate groups for \"best\" selection. The first is for Classes \"1b\" and \"1d\", which means that if there are multiple assignments for the same site in those classes, the one with the highest metric (here Rscore) was selected. The second is for Class 4, and the same selection process was followed within that Class, picking the single assignment with the highest Rscore.  \n",
    "\n",
    "Since some sites were mapped in Classes 1a and 1b, a final filtering is applied in which the Class 1a assignments were retained in preference to assignments for the same sites in Class 1b. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "df48ce6f-62b8-4ebf-87a0-9400a339f646",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting all of Class 1a and 2\n",
      "Extracting best of Class 1b and 1d\n",
      "Extracting best of Class 4\n"
     ]
    }
   ],
   "source": [
    "catalog = catalog.query(\"status not in ['Untrusted', 'Rejected']\")\n",
    "\n",
    "groups = [\n",
    "    {\"whole\": [\"1a\", \"2\"]}, \n",
    "    {\"best\": [\"1b\", \"1d\"]}, \n",
    "    {\"best\": \"4\"}\n",
    "]\n",
    "\n",
    "keep = [\"name\", \"Class\", \"assignment_id\", \"Labeller\", \"status\", \"Score\", \n",
    "        \"N\", \"Area\", \"Qscore\", \"Rscore\", \"x\", \"y\", \"farea\", \"nflds\", \n",
    "       \"chip\"]\n",
    "\n",
    "label_catalog = filter_catalog(catalog, groups, \"Rscore\", keep)\n",
    "\n",
    "# there are some duplicates of Class 1a in Classes 1b/d, so we'll drop those\n",
    "label_catalog.drop_duplicates(\"name\", inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40e65814-2d6a-4bb8-8745-d03a1281ea03",
   "metadata": {},
   "source": [
    "The final class counts were as follows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c137e4e8-f0e6-4d87-84ff-8c4401239a7b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Class\n",
       "2     30772\n",
       "4       990\n",
       "1d      905\n",
       "1a      797\n",
       "1b      282\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_catalog.value_counts(\"Class\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65b8b052-d0b3-4373-afd0-51b2d9b6b78c",
   "metadata": {},
   "source": [
    "## Making label chips\n",
    "\n",
    "The next step was to convert the polygons into chips. This requires the geoparquet file containing the field polygons. We will use the filtered label catalog to get the image chip that corresponds to the labelled site, and the convert the polygons for each site to a 3-class label that has the same dimensions as the image chip. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0b615645-7db0-4567-8388-4a26b4c86fdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "fields = gpd.read_parquet(Path(proj_dir) /\\\n",
    "                          \"data/processed/mapped_fields_final.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f7addef9-e2a2-4261-9224-6a9b658069f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings(\n",
    "    'ignore', \n",
    "    message=\"Geometry is in a geographic CRS. Results from \" +\\\n",
    "    \"'buffer' are likely incorrect.\"\n",
    ")\n",
    "log = open(log_path, \"a+\")\n",
    "print(f\"\\nStarting at {dt.now()}\\n\", file=log, flush=True)\n",
    "lbls = []\n",
    "for i, row in label_catalog.iterrows():\n",
    "    lbls.append(threeclass_label(row, label_dir=label_dir, fields=fields, \n",
    "                                 log=log, overwrite=False))\n",
    "\n",
    "print(f\"\\nFinished at {dt.now()}\", file=log, flush=True)\n",
    "log.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cacf71b2-a8df-4a68-832b-5df8d05fe467",
   "metadata": {},
   "source": [
    "### Save catalog"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2d0de3ae-be29-4745-a295-c9711f80050c",
   "metadata": {},
   "outputs": [],
   "source": [
    "label_catalog_final = pd.concat(lbls).reset_index(drop=True)\n",
    "label_catalog_final.to_csv(Path(final_dir) / \"label-catalog-filtered.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "38800c18-4403-4361-b498-bde77564684c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>Class</th>\n",
       "      <th>assignment_id</th>\n",
       "      <th>Labeller</th>\n",
       "      <th>status</th>\n",
       "      <th>Score</th>\n",
       "      <th>N</th>\n",
       "      <th>Area</th>\n",
       "      <th>Qscore</th>\n",
       "      <th>Rscore</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>farea</th>\n",
       "      <th>nflds</th>\n",
       "      <th>chip</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NG0239934</td>\n",
       "      <td>2</td>\n",
       "      <td>122</td>\n",
       "      <td>10</td>\n",
       "      <td>Approved</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.61966</td>\n",
       "      <td>0.811741</td>\n",
       "      <td>6.4365</td>\n",
       "      <td>12.7425</td>\n",
       "      <td>0.449518</td>\n",
       "      <td>26</td>\n",
       "      <td>NG0239934-2022-03-15.tif</td>\n",
       "      <td>NG0239934-2022-03-15-122.tif</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NG0781094</td>\n",
       "      <td>2</td>\n",
       "      <td>175</td>\n",
       "      <td>10</td>\n",
       "      <td>Approved</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.61966</td>\n",
       "      <td>0.811741</td>\n",
       "      <td>4.7015</td>\n",
       "      <td>11.4925</td>\n",
       "      <td>0.466465</td>\n",
       "      <td>13</td>\n",
       "      <td>NG0781094-2017-02-15.tif</td>\n",
       "      <td>NG0781094-2017-02-15-175.tif</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        name Class  assignment_id Labeller    status  Score   N  Area  \\\n",
       "0  NG0239934     2            122       10  Approved    NaN NaN   NaN   \n",
       "1  NG0781094     2            175       10  Approved    NaN NaN   NaN   \n",
       "\n",
       "    Qscore    Rscore       x        y     farea  nflds  \\\n",
       "0  0.61966  0.811741  6.4365  12.7425  0.449518     26   \n",
       "1  0.61966  0.811741  4.7015  11.4925  0.466465     13   \n",
       "\n",
       "                       chip                         label  \n",
       "0  NG0239934-2022-03-15.tif  NG0239934-2022-03-15-122.tif  \n",
       "1  NG0781094-2017-02-15.tif  NG0781094-2017-02-15-175.tif  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_catalog_final.iloc[0:2]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "518a52ca-9a62-4789-be14-45a51e4649e5",
   "metadata": {},
   "source": [
    "## Display labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15196ab9-4b97-4974-ae96-b7e31fcc5c42",
   "metadata": {},
   "source": [
    "The following viewer can be used to display labels against the images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "8421dd72-6887-4acb-b809-5d26fc641eb5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0ee3d6d79dab4629a7c00b015b39513b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map(center=[7.6525, 8.4565], controls=(ZoomControl(options=['position', 'zoom_in_text', 'zoom_in_title', 'zoomâ€¦"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "view_random_label(label_catalog_final, label_dir, chip_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "595ffe99-7fc4-4fe1-8ddc-8975428fcc28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(825395, 6)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fields.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74443fee-6b38-4569-a963-0d21072836be",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
